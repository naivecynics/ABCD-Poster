@article{Birring2008LCM,
  author  = {Birring, S. S. and Fleming, T. and Matos, S. and Raj, A. A. and Evans, D. H. and Pavord, I. D.},
  title   = {The Leicester Cough Monitor: Preliminary validation of an automated cough detection system in chronic cough},
  journal = {European Respiratory Journal},
  year    = {2008},
  volume  = {31},
  number  = {5},
  pages   = {1013--1018},
  doi     = {10.1183/09031936.00057407},
  issn    = {0903-1936},
  url     = {https://erj.ersjournals.com/content/31/5/1013}
}

@article{McGuinness2012VitaloJAK,
  author  = {McGuinness, K. and Gourlay, N. and Birring, S. S. and Pavord, I. D.},
  title   = {Validation of the VitaloJAK\textsuperscript{\texttrademark} 24 Hour Ambulatory Cough Monitor},
  journal = {Thorax},
  year    = {2012},
  volume  = {67},
  number  = {Suppl~2},
  pages   = {A131},
  doi     = {10.1136/thoraxjnl-2012-202678.311}
}

@article{Barata2023Smartphone,
  author  = {Barata, F. and Cleres, D. and Tinschert, P. and Shih, C. I. and Rassouli, F. and Boesch, M. and Brutsche, M. and Fleisch, E.},
  title   = {Nighttime Continuous Contactless Smartphone-Based Cough Monitoring for the Ward: Validation Study},
  journal = {JMIR Formative Research},
  year    = {2023},
  volume  = {7},
  pages   = {e38439},
  doi     = {10.2196/38439},
  pmid    = {36655551},
  url     = {https://formative.jmir.org/2023/1/e38439}
}

@inproceedings{Chen2024RobustCough,
  author    = {Yuhan Chen and Jeffrey Barahona and Iype Eldho and Yanbing Yu},
  title     = {Robust Multimodal Cough and Speech Detection Using Wearables: A Preliminary Analysis},
  booktitle = {Proceedings of the 2024 IEEE Engineering in Medicine and Biology Conference (EMBC)},
  year      = {2024},
  note      = {Pre-print available on ResearchGate, DOI pending}
}

@article{Diab2024Accel,
  author  = {Diab, M. and Albini, G. and Zennaro, F. and Orlandic, L. and others},
  title   = {Feature Evaluation of Accelerometry Signals for Cough Detection},
  journal = {Sensors},
  year    = {2024},
  volume  = {24},
  number  = {3},
  pages   = {678},
  doi     = {10.3390/s24030678},
  url     = {https://www.mdpi.com/10995234}
}

@article{Drugman2020AudioContact,
  author  = {Drugman, T. and Urbain, J. and Bauwens, N. and Chessini, R. and Aubriot, A.-S. and Lebecque, P. and Dutoit, T.},
  title   = {Audio and Contact Microphones for Cough Detection},
  journal = {IEEE Journal of Biomedical and Health Informatics},
  year    = {2020},
  volume  = {24},
  number  = {4},
  pages   = {1012--1021},
  doi     = {10.1109/JBHI.2020.2985908},
  url     = {https://arxiv.org/abs/2005.05313}
}

@article{Li2019ChewingBC,
  author  = {Li, K. and Wang, Y. and Wu, J. and others},
  title   = {Chewing Monitoring with Bone-Conduction Microphone for Body-Area Networks},
  journal = {IEEE Access},
  year    = {2019},
  volume  = {7},
  pages   = {78591--78601},
  doi     = {10.1109/ACCESS.2019.2922731}
}

@article{Wang2022Fusion,
  author    = {Wang, H. and Zhang, X. and Wang, D.},
  title     = {Attention-Based Fusion for Bone-Conducted and Air-Conducted Speech Enhancement in the Complex Domain},
  booktitle = {Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  year      = {2022},
  pages     = {7757--7761},
  doi       = {10.1109/icassp43922.2022.9746374},
  note      = {Epub 2022 Apr 27},
  pmid      = {40313328},
  pmcid     = {PMC12045135}
}

@article{Howard2017MobileNet,
  author  = {Howard, A. G. and Zhu, M. and Chen, B. and others},
  title   = {MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications},
  journal = {arXiv preprint arXiv:1704.04861},
  year    = {2017},
  url     = {https://arxiv.org/abs/1704.04861}
}

@inproceedings{Sandler2018MobileNetV2,
  author    = {Sandler, M. and Howard, A. and Zhu, M. and Zhmoginov, A. and Chen, L.-C.},
  title     = {MobileNetV2: Inverted Residuals and Linear Bottlenecks},
  booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2018},
  pages     = {4510--4520},
  doi       = {10.1109/CVPR.2018.00474}
}

@article{Howard2019MobileNetV3,
  author  = {Howard, A. and Sandler, M. and Chu, G. and others},
  title   = {Searching for MobileNetV3},
  journal = {Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
  year    = {2019},
  pages   = {1314--1324},
  doi     = {10.1109/ICCV.2019.00140}
}

@misc{Google2021YAMNet,
  author = {{Google Research}},
  title  = {YAMNet: A Pre-trained Model for Audio Event Classification},
  year   = {2021},
  note   = {GitHub repository, \url{https://github.com/tensorflow/models/tree/master/research/audioset/yamnet}}
}

@article{Kong2020PANNs,
  author  = {Kong, Q. and Cao, Y. and Iqbal, T. and Wang, Y. and Plumbley, M. D. and Wang, W.},
  title   = {PANNs: Large-Scale Pre-Trained Audio Neural Networks for Audio Pattern Recognition},
  journal = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  year    = {2020},
  volume  = {28},
  pages   = {2880--2894},
  doi     = {10.1109/TASLP.2020.3030497}
}

@inproceedings{Oord2018CPC,
  author    = {van den Oord, A. and Li, Y. and Vinyals, O.},
  title     = {Representation Learning with Contrastive Predictive Coding},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year      = {2018}
}

@inproceedings{Chen2020SimCLR,
  author    = {Chen, T. and Kornblith, S. and Norouzi, M. and Hinton, G.},
  title     = {A Simple Framework for Contrastive Learning of Visual Representations},
  booktitle = {Proceedings of the 37th International Conference on Machine Learning (ICML)},
  year      = {2020},
  pages     = {1597--1607}
}

@inproceedings{Niizumi2021BYOLA,
  author    = {Niizumi, D. and Sawada, H. and Koizumi, Y. and Qiu, W. and Harada, N.},
  title     = {BYOL-A: Self-Supervised Audio Representation Learning without a Pre-text Task},
  booktitle = {IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)},
  year      = {2021},
  pages     = {3060--3064},
  doi       = {10.1109/ICASSP39728.2021.9414639}
}

@article{Baevski2020Wav2vec2,
  author  = {Baevski, A. and Zhou, H. and Mohamed, A. and Auli, M.},
  title   = {wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations},
  journal = {Advances in Neural Information Processing Systems},
  year    = {2020},
  volume  = {33},
  pages   = {12449--12460}
}

@inproceedings{Zhang2021SpeechSimCLR,
  author    = {Zhang, Q. and Du, J. and Lee, C.-H.},
  title     = {SpeechSimCLR: Combining Contrastive Learning and Supervised Learning for Speech Emotion Recognition},
  booktitle = {IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)},
  year      = {2021},
  pages     = {1066--1073},
  doi       = {10.1109/ASRU51503.2021.9688144}
}

@article{Otoshi2021Strain,
  title = {A Novel Automatic Cough Frequency Monitoring System Combining a Triaxial Accelerometer and a Stretchable Strain Sensor},
  author = {Otoshi, Takehiro and Nagano, Tatsuya and Izumi, Shintaro and Hazama, Daisuke and Katsurada, Naoko and Yamamoto, Masatsugu and Tachihara, Motoko and Kobayashi, Kazuyuki and Nishimura, Yoshihiro},
  date = {2021-05-11},
  journaltitle = {Scientific Reports},
  shortjournal = {Scientific Reports},
  volume = {11},
  number = {1},
  pages = {9973},
  issn = {2045-2322},
  doi = {10.1038/s41598-021-89457-0},
  url = {https://doi.org/10.1038/s41598-021-89457-0},
  abstract = {Objective evaluations of cough frequency are considered important for assessing the clinical state of patients with respiratory diseases. However, cough monitors with audio recordings are rarely used in clinical settings. Issues regarding privacy and background noise with audio recordings are barriers to the wide use of these monitors; to solve these problems, we developed a novel automatic cough frequency monitoring system combining a triaxial accelerator and a stretchable strain sensor. Eleven healthy adult volunteers and 10 adult patients with cough were enrolled. The participants wore two devices for 30~min for the cough measurements. An accelerator was attached to the epigastric region, and a stretchable strain sensor was worn around their neck. When the subjects coughed, these devices displayed specific waveforms. The data from all the participants were categorized into a training dataset and a test dataset. Using a variational autoencoder, a machine learning algorithm with deep learning, the components of the test dataset were automatically judged as being a “cough unit” or “non-cough unit”. The sensitivity and specificity in detecting coughs were 92\% and 96\%, respectively. Our cough monitoring system has the potential to be widely used in clinical settings without any concerns regarding privacy or background noise.}
}

@article{Pahar2021BedAccel,
  author    = {Pahar, M. and Miranda, I. and Diacon, A. and Niesler, T.},
  title     = {Automatic Non-Invasive Cough Detection based on Accelerometer and Audio Signals},
  journal   = {Journal of Signal Processing Systems},
  volume    = {94},
  number    = {8},
  pages     = {821--835},
  year      = {2022},
  doi       = {10.1007/s11265-022-01748-5},
  pmid      = {35341095},
  pmcid     = {PMC8934184},
  note      = {Epub 2022 Mar 19}
}

@inproceedings{Orlandic2023EdgeDataset,
  author={Orlandic, Lara and Thevenot, Jérôme and Teijeiro, Tomas and Atienza, David},
  booktitle={2023 45th Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)}, 
  title={A Multimodal Dataset for Automatic Edge-AI Cough Detection}, 
  year={2023},
  volume={},
  number={},
  pages={1-7},
  keywords={Performance evaluation;Privacy;Sensitivity;Wearable computers;Image edge detection;Multimodal sensors;Neural networks},
  doi={10.1109/EMBC40787.2023.10340413}}
}

@article{Wang2022ABCS,
  author  = {Wang, X. and Xu, J. and Li, X. and others},
  title   = {ABCS: A 42-Hour Air–Bone Conduction Speech Corpus for Robust Speech Enhancement},
  journal = {IEEE Journal of Selected Topics in Signal Processing},
  year    = {2022},
  volume  = {16},
  number  = {6},
  pages   = {1340--1354},
  doi     = {10.1109/JSTSP.2022.3199912}
}

@misc{Liu2025PMUT,
doi = {10.21227/p5vj-qq91},
url = {https://dx.doi.org/10.21227/p5vj-qq91},
author = {Chongbin Liu},
publisher = {IEEE Dataport},
title = {A PMUT-Based Bone Conduction Microphone System for Enhancing Speech Recognition Accuracy},
}

@misc{Albini2024CoughE,
   title={Cough-E: A multimodal, privacy-preserving cough detection algorithm for the edge},
   ISSN={2168-2208},
   url={http://dx.doi.org/10.1109/JBHI.2025.3577507},
   DOI={10.1109/jbhi.2025.3577507},
   journal={IEEE Journal of Biomedical and Health Informatics},
   publisher={Institute of Electrical and Electronics Engineers (IEEE)},
   author={Albini, Stefano and Orlandic, Lara and Dan, Jonathan and Thevenot, Jérôme and Teijeiro, Tomas and Constantinescu, Denisa-Andreea and Atienza, David},
   year={2025},
   pages={1–15}
}

@misc{Hauret2025Vibravox,
  author = {Hauret, Julien and Olivier, Malo and Joubaud, Thomas and Langrenne, Christophe and Poirée, Sarah and Zimpfer, Véronique and Bavu, Eric},
  year = {2024},
  month = {07},
  pages = {},
  title = {Vibravox: A Dataset of French Speech Captured with Body-conduction Audio Sensors},
  doi = {10.48550/arXiv.2407.11828}
}

@misc{Hosain2024EmoBone,
  author = {Hosain, Md and Sugiura, Yosuke and Rahman, M. Shahidur and Shimamura, Tetsuya},
  year = {2024},
  month = {05},
  pages = {1-15},
  title = {EmoBone: A Multinational Audio Dataset of Emotional Bone Conducted Speech},
  volume = {19},
  journal = {IEEJ Transactions on Electrical and Electronic Engineering},
  doi = {10.1002/tee.24110}
}

